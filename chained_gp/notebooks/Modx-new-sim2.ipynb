{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motorcycle dataset analysis, found at http://vincentarelbundock.github.io/Rdatasets/datasets.html under 'mcycle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import GPy\n",
    "import numpy as np\n",
    "from hetgp import HetGP\n",
    "from svgp_multi import SVGPMulti\n",
    "from sklearn.metrics import (r2_score, mean_squared_error, mean_absolute_error)\n",
    "data_dir = './modx_data/'\n",
    "\n",
    "def regression_metrics(y_true: np.array, y_pred: np.array):\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        'Mean Squared Error (MSE)': np.float32(mse),\n",
    "        'Mean Absolute Error (MAE)': np.float32(mae),\n",
    "        'R-squared (R2)': np.float32(r2),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restarts = 10\n",
    "n_folds = 5\n",
    "Ms = ['all'] #, 100]\n",
    "#These are just starting values, lengthscales will also be randomized\n",
    "f_rbf_len = 1 # 0.3\n",
    "f_rbf_var = 0.5 # 0.5\n",
    "g_rbf_len = 1 # 0.5\n",
    "g_rbf_var = 0.5 # 0.5\n",
    "\n",
    "# This is the log of mean of the posterior of the scale parameter, so we set it\n",
    "# to be the log of roughly what we expect the scale parameter to be if it were\n",
    "# constant\n",
    "\n",
    "gauss_noise = 0.1\n",
    "g_mean_val = None  # np.log(gauss_noise)\n",
    "g_bias_var = None\n",
    "f_bias_var = None # ['mean']\n",
    "fixZ = True\n",
    "preopt_scg_iters = 100\n",
    "preopt_restarts = 3\n",
    "scg_iters = 50\n",
    "max_iters = 250\n",
    "num_samples = 100000\n",
    "gtol = 1e-5\n",
    "ftol = 0\n",
    "xtol = 0\n",
    "starting_df = 4.0\n",
    "optimize_df = True\n",
    "\n",
    "fold = 0\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "name = 'sim2.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_tsv(path: str, name: str):\n",
    "    return pd.read_csv(os.path.join(path, name), sep='\\t')\n",
    "\n",
    "def std_matrices(*mts):\n",
    "    std_mts = []\n",
    "    for mats in mts:\n",
    "        if isinstance(mats, np.ndarray):  # Single matrix case\n",
    "            mats = [mats]\n",
    "        for mat in mats:\n",
    "            min_vals = np.min(mat, axis=0)\n",
    "            max_vals = np.max(mat, axis=0)\n",
    "            std_mat = (mat - min_vals) / (max_vals - min_vals)\n",
    "            std_mts.append(std_mat)\n",
    "    return tuple(std_mts)\n",
    "\n",
    "def holdout_split(\n",
    "        df,\n",
    "        test_size: float = 0.2,\n",
    "        random_state: int = None,\n",
    "    ):\n",
    "    y = df.Y.values\n",
    "    x = df.values[:, :-1]\n",
    "    return train_test_split(\n",
    "            x, y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape:  (240, 12)\n",
      "test shape:  (60, 12)\n",
      "All:  (300, 12)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, Xtrain, Ytrain, Xtest, Ytest):\n",
    "        self.Xtrain, self.Ytrain, self.Xtest, self.Ytest = Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "def load_modx(seed):\n",
    "\n",
    "    df = read_tsv(path=data_dir, name=name)    \n",
    "    Y = df.Y.values\n",
    "    X = df.values[:, :-1]\n",
    "    Xtrain, Xtest, Ytrain, Ytest = std_matrices(\n",
    "        holdout_split(\n",
    "            df=read_tsv(path=data_dir, name=name),\n",
    "            random_state=seed\n",
    "            )\n",
    "        )\n",
    "    Ytrain = Ytrain[:, None]\n",
    "    Ytest = Ytest[:, None]\n",
    "    print(\"training shape: \", Xtrain.shape)\n",
    "    print(\"test shape: \", Xtest.shape)\n",
    "    print(\"All: \", X.shape)\n",
    "    print(Xtrain.shape[0] + Xtest.shape[0] - X.shape[0])\n",
    "    return Dataset(Xtrain=Xtrain, Ytrain=Ytrain, Xtest=Xtest, Ytest=Ytest), X, Y\n",
    "\n",
    "dataset, X, Y = load_modx(seed)\n",
    "\n",
    "Xtrain = dataset.Xtrain\n",
    "Ytrain = dataset.Ytrain\n",
    "Xtest = dataset.Xtest\n",
    "Ytest = dataset.Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters gauss_single.kernf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreOptimizing gauss  \n",
      "Name : gauss_single\n",
      "Objective : 51.21017624901796\n",
      "Number of Parameters : 2895\n",
      "Number of Optimization Parameters : 2894\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mgauss_single.              \u001b[0;0m  |      value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |  (240, 12)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |        0.5  |      +ve      |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |      (12,)  |      +ve      |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |      0.001  |   +ve fixed   |        \n",
      "  \u001b[1mGaussian_noise.variance    \u001b[0;0m  |        0.1  |      +ve      |        \n",
      "  \u001b[1mindex\u001b[0;0m  |  gauss_single.kernf.kernf_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[10] \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[11] \u001b[0;0m  |                                1.00000000  |      +ve      |        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters gauss_single.Gaussian_noise.variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i     f              |g|        \n",
      "WARNING: l-bfgs-b doesn't have an xtol arg, so I'm going to ignore it\n",
      "WARNING: l-bfgs-b doesn't have an ftol arg, so I'm going to ignore it\n",
      "    01s25  009  -2.290280e+02   3.621971e+03 \n",
      "    06s55  042  -3.056613e+02   1.530431e+02 \n",
      "    12s04  077  -3.405432e+02   2.496770e+01 \n",
      "    16s18  102  -3.407833e+02   3.169021e+00 \n",
      "Runtime:     16s18\n",
      "Optimization status: Maximum number of f evaluations reached\n",
      "\n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i     f              |g|        \n",
      "WARNING: l-bfgs-b doesn't have an xtol arg, so I'm going to ignore it\n",
      "WARNING: l-bfgs-b doesn't have an ftol arg, so I'm going to ignore it\n",
      "    00s14  001  -3.407833e+02   3.465739e+00 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/rbarbano/projects/dev/ChainedGP/myenv/lib/python3.6/site-packages/paramz/transformations.py:111: RuntimeWarning:overflow encountered in expm1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    02s35  016  -3.408613e+02   2.130894e-01 \n",
      "    07s75  051  -3.408625e+02   6.434973e-01 \n",
      "    10s88  070  -3.408657e+02   3.378022e-01 \n",
      "Runtime:     10s88\n",
      "Optimization status: Converged\n",
      "\n",
      "Found best gauss model\n",
      "\n",
      "Name : gauss_single\n",
      "Objective : -340.86566922465863\n",
      "Number of Parameters : 2895\n",
      "Number of Optimization Parameters : 2895\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mgauss_single.              \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |               (240, 12)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |       45.09503036934604  |      +ve      |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |                   (12,)  |      +ve      |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |  5.562684646268137e-309  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance    \u001b[0;0m  |    0.000323786945290136  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    01s20  0008  -3.408658e+02   1.395515e-01 \n",
      "    04s44  0030  -3.408675e+02   3.664619e-01 \n",
      "Runtime:     04s44\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : gauss_single\n",
      "Objective : -340.8674803574613\n",
      "Number of Parameters : 2895\n",
      "Number of Optimization Parameters : 2894\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mgauss_single.              \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |               (240, 12)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |       45.08088150955436  |      +ve      |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |                   (12,)  |      +ve      |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |  5.562684646268137e-309  |   +ve fixed   |        \n",
      "  \u001b[1mGaussian_noise.variance    \u001b[0;0m  |   0.0003241264501987581  |      +ve      |        \n",
      "  \u001b[1mindex\u001b[0;0m  |  gauss_single.kernf.kernf_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                                1.05154797  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                                7.46872932  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                              804.80761633  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                              526.24241365  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                                1.08031904  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                              532.18647295  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                              620.39396361  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                                7.06621110  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                              904.76121361  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                              518.38983209  |      +ve      |        \n",
      "  \u001b[1m[10] \u001b[0;0m  |                                6.82089836  |      +ve      |        \n",
      "  \u001b[1m[11] \u001b[0;0m  |                                1.04854434  |      +ve      |        \n",
      "[[0.44781279]\n",
      " [0.22096082]\n",
      " [0.15679191]\n",
      " [0.37996966]\n",
      " [0.10664173]\n",
      " [0.32025963]\n",
      " [0.24582193]\n",
      " [0.1326823 ]\n",
      " [0.40176801]\n",
      " [0.08724006]\n",
      " [0.25608603]\n",
      " [0.22487768]\n",
      " [0.3559178 ]\n",
      " [0.13478151]\n",
      " [0.53984128]\n",
      " [0.11220084]\n",
      " [0.26714672]\n",
      " [0.27180952]\n",
      " [0.10301081]\n",
      " [0.3548345 ]\n",
      " [0.03944214]\n",
      " [0.2412952 ]\n",
      " [0.12308065]\n",
      " [0.38130867]\n",
      " [0.59270866]\n",
      " [0.44020434]\n",
      " [0.19042103]\n",
      " [0.17783794]\n",
      " [0.1345895 ]\n",
      " [0.23762396]\n",
      " [0.1644444 ]\n",
      " [0.29536297]\n",
      " [0.35933541]\n",
      " [0.14369141]\n",
      " [0.12964494]\n",
      " [0.15865954]\n",
      " [0.0714925 ]\n",
      " [0.31660481]\n",
      " [0.74281228]\n",
      " [0.65525019]\n",
      " [0.22855058]\n",
      " [0.34496234]\n",
      " [0.20653474]\n",
      " [0.09132652]\n",
      " [0.08933124]\n",
      " [0.4608869 ]\n",
      " [0.29742447]\n",
      " [0.21788352]\n",
      " [0.13246295]\n",
      " [0.14576987]\n",
      " [0.40849695]\n",
      " [0.07104728]\n",
      " [0.08174096]\n",
      " [0.28907888]\n",
      " [0.26161678]\n",
      " [0.1353985 ]\n",
      " [0.11530597]\n",
      " [0.26337194]\n",
      " [0.13300963]\n",
      " [0.169184  ]]\n",
      "train: {'Mean Squared Error (MSE)': 0.0050623035, 'Mean Absolute Error (MAE)': 0.051860224, 'R-squared (R2)': 0.86840457}\n"
     ]
    }
   ],
   "source": [
    "def build_kernf(D, dataset, bias, f_rbf_len, f_rbf_var, seed, fold):\n",
    "    kernf = GPy.kern.RBF(D, variance=f_rbf_var,\n",
    "                         lengthscale=np.ones(D)*f_rbf_len, ARD=True,\n",
    "                         name='kernf_rbf')\n",
    "    kernf += GPy.kern.White(1, variance=0.001, name='f_white')\n",
    "    if bias is not None:\n",
    "        if bias == 'mean':\n",
    "            f_bias_var = dataset.Ytrain.mean()\n",
    "        else:\n",
    "            f_bias_var = bias\n",
    "            kernf += GPy.kern.Bias(1, variance=f_bias_var, name='f_bias')\n",
    "    kernf.f_white.fix()\n",
    "    kernf.name = 'kernf'\n",
    "    return kernf\n",
    "\n",
    "def build_kerng(D, g_bias, g_rbf_len, seed, fold):\n",
    "    # Needs white or variance doesn't checkgrad!\n",
    "    kerng = GPy.kern.RBF(D, variance=g_rbf_var,\n",
    "                         lengthscale=np.ones(D)*g_rbf_len, ARD=True,\n",
    "                         name='kerng_rbf')\n",
    "    kerng += GPy.kern.White(1, variance=0.001, name='g_white')\n",
    "    if g_bias is not None:\n",
    "        kerng += GPy.kern.Bias(1, variance=g_bias, name='g_bias')\n",
    "    kerng.g_white.fix()\n",
    "    kerng.name = 'kerng'\n",
    "    return kerng\n",
    "\n",
    "from scipy.cluster.vq import kmeans as scipy_kmeans\n",
    "\n",
    "def kmeans(dataset, k, seed):\n",
    "    Z, _ = scipy_kmeans(dataset.Xtrain, k)\n",
    "    return Z\n",
    "\n",
    "def build_gauss_model(dataset, Z, fixZ, bias, f_rbf_len, f_rbf_var, seed, fold):\n",
    "    D = dataset.Xtrain.shape[1]\n",
    "    kernf = build_kernf(D, dataset, bias, f_rbf_len, f_rbf_var, seed, fold)\n",
    "    m_gauss = GPy.models.SparseGPRegression(dataset.Xtrain.copy(), dataset.Ytrain.copy(), Z=Z.copy(), kernel=kernf)\n",
    "    m_gauss.name='gauss_single'\n",
    "    m_gauss.likelihood.variance[:] = gauss_noise\n",
    "    return m_gauss\n",
    "\n",
    "def preopt_gauss_scheme(m):\n",
    "    m.kernf.constrain_positive()\n",
    "    m.likelihood.variance.constrain_positive()\n",
    "    if hasattr(m, 'Z'):\n",
    "        m.Z.fix()\n",
    "    m.optimize('bfgs', max_iters=preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "    if hasattr(m, 'Z'):\n",
    "        m.Z.unfix()\n",
    "    m.optimize('bfgs', max_iters=5*preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "    return m\n",
    "\n",
    "def preopt_gauss(dataset, Z, fixZ, bias, f_rbf_len, f_rbf_var, seed, fold):\n",
    "    m = build_gauss_model(dataset, Z, fixZ, bias, f_rbf_len, f_rbf_var, seed, fold)\n",
    "    print(\"PreOptimizing gauss \", m)\n",
    "    print(m.kernf.kernf_rbf.lengthscale)\n",
    "    best_m = preopt_gauss_scheme(m)\n",
    "    print(\"Found best gauss model\")\n",
    "    print(best_m)\n",
    "    return best_m[:]\n",
    "\n",
    "m1_opt = preopt_gauss(dataset, Xtrain.copy(), fixZ, f_bias_var, f_rbf_len, f_rbf_var, seed, fold)\n",
    "m1 = build_gauss_model(dataset, Xtrain.copy(), fixZ, f_bias_var, f_rbf_len, f_rbf_var, seed, fold)\n",
    "m1[:] = m1_opt\n",
    "\n",
    "m1.Z.unfix()\n",
    "m1.optimize('bfgs', max_iters=3000, messages=1)\n",
    "print(m1)\n",
    "print(m1.kernf.kernf_rbf.lengthscale)\n",
    "mu_gauss, var_gauss = m1.predict(Xtest)\n",
    "\n",
    "print(mu_gauss)\n",
    "metrics = regression_metrics(y_true=Ytest, y_pred=mu_gauss)\n",
    "print(f'train: {metrics}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.36287782423458503\n",
      "  \u001b[1mindex\u001b[0;0m  |  gauss_single.kernf.kernf_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                                1.05154797  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                                7.46872932  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                              804.80761633  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                              526.24241365  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                                1.08031904  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                              532.18647295  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                              620.39396361  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                                7.06621110  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                              904.76121361  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                              518.38983209  |      +ve      |        \n",
      "  \u001b[1m[10] \u001b[0;0m  |                                6.82089836  |      +ve      |        \n",
      "  \u001b[1m[11] \u001b[0;0m  |                                1.04854434  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "print(m1.log_predictive_density(Xtest, Ytest).mean())\n",
    "print(m1.kernf.kernf_rbf.lengthscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_multi_lengthscales(X_):\n",
    "    normed_X = (X_.max(0) - X_.min(0))/X_.std(0)\n",
    "    # print(normed_X)\n",
    "    f_lengthscales = np.random.uniform(size=X_.shape[1])*(0.4/normed_X) + 0.001\n",
    "    g_lengthscales = np.random.uniform(size=X_.shape[1])*(0.4/normed_X) + 0.001\n",
    "    # print(f_lengthscales)\n",
    "    return f_lengthscales, g_lengthscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name : multi_gauss\n",
      "Objective : 7623.022000324801\n",
      "Number of Parameters : 61228\n",
      "Number of Optimization Parameters : 58320\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mmulti_gauss.               \u001b[0;0m  |       value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |   (240, 12)  |     fixed     |        \n",
      "  \u001b[1mq_u_means                  \u001b[0;0m  |    (240, 2)  |               |        \n",
      "  \u001b[1mqf_u_chols                 \u001b[0;0m  |  (28920, 2)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |         0.5  |   +ve fixed   |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |       (12,)  |   +ve fixed   |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |       0.001  |   +ve fixed   |        \n",
      "  \u001b[1mkerng.kerng_rbf.variance   \u001b[0;0m  |         0.5  |   +ve fixed   |        \n",
      "  \u001b[1mkerng.kerng_rbf.lengthscale\u001b[0;0m  |       (12,)  |   +ve fixed   |        \n",
      "  \u001b[1mkerng.g_white.variance     \u001b[0;0m  |       0.001  |   +ve fixed   |        \n",
      "Running Scaled Conjugate Gradients Code:\n",
      "  runtime   i     f              |g|        \n",
      "    00s18  005   2.469865e+03   3.427449e+05 \n",
      "    01s19  029   2.892408e+02   2.642315e+03 \n",
      "    06s38  128   1.145653e+02   1.840526e+02 \n",
      "    12s59  246   4.276798e+01   1.471592e+02 \n",
      "    15s64  302   3.548408e+01   5.666904e+01 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters multi_gauss.kernf\n",
      "reconstraining parameters multi_gauss.kerng\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runtime:     15s64\n",
      "Optimization status: maxiter exceeded\n",
      "\n",
      "Running Scaled Conjugate Gradients Code:\n",
      "  runtime   i     f              |g|        \n",
      "    00s11  001   3.548408e+01   7.339953e+01 \n",
      "    02s21  023  -3.500383e+01   1.011997e+04 \n",
      "    04s39  043  -4.783137e+01   5.140690e+04 \n",
      "    13s88  146  -1.012918e+02   9.882919e+02 \n",
      "    30s76  302  -1.481911e+02   8.106327e+02 \n",
      "Runtime:     30s76\n",
      "Optimization status: maxiter exceeded\n",
      "\n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i     f              |g|        \n",
      "WARNING: l-bfgs-b doesn't have an xtol arg, so I'm going to ignore it\n",
      "WARNING: l-bfgs-b doesn't have an ftol arg, so I'm going to ignore it\n",
      "    00s15  000  -1.481911e+02   9.494269e+02 \n",
      "    02s26  018  -1.512348e+02   3.580820e+02 \n",
      "    09s67  079  -1.816008e+02   1.526087e+02 \n",
      "    30s42  238  -2.002423e+02   8.439944e+01 \n",
      "    50s51  381  -2.059785e+02   1.414499e+01 \n",
      " 01m08s77  502  -2.085446e+02   2.011908e+01 \n",
      "Runtime:  01m08s77\n",
      "Optimization status: Maximum number of f evaluations reached\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make the kernels : \n",
    "D = dataset.Xtrain.shape[1]\n",
    "kernf = build_kernf(D, dataset, f_bias_var, f_rbf_len, f_rbf_var, seed, fold)\n",
    "kerng = build_kerng(D, g_bias_var, g_rbf_len, seed, fold)\n",
    "kern = [kernf, kerng]\n",
    "mean_functions = [None, None]\n",
    "likelihood = HetGP()\n",
    "\n",
    "Z = dataset.Xtrain.copy()\n",
    "\n",
    "# Make the model : \n",
    "m2 = SVGPMulti(dataset.Xtrain.copy(), dataset.Ytrain.copy(), Z.copy(), kern_list=kern,\n",
    "                    likelihood=likelihood, mean_functions=mean_functions, name='multi_gauss')\n",
    "\n",
    "\n",
    "def pretrain_multi(m, randomize=False):\n",
    "    if randomize:\n",
    "        f_lens, g_lens = random_multi_lengthscales(m.X.values)\n",
    "        m.kernf.kernf_rbf.lengthscale[:] = f_lens\n",
    "        m.kernf.kernf_rbf.variance[:] = f_rbf_var\n",
    "        m.kerng.kerng_rbf.lengthscale[:] = g_lens\n",
    "        m.kerng.kerng_rbf.variance[:] = g_rbf_var\n",
    "    m.kernf.fix()\n",
    "    m.kerng.fix()\n",
    "    if hasattr(m, 'Z'):\n",
    "        m.Z.fix()\n",
    "    if hasattr(m, 'constmap'):\n",
    "        m.constmap.fix()\n",
    "    print(m)\n",
    "\n",
    "    # Optimize model with fixed parameters to get latent functions in place\n",
    "    m.optimize('scg', max_iters=1*preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "    \n",
    "    # Constrain all kernel parameters positive and reoptimize\n",
    "    m.kernf.constrain_positive()\n",
    "    m.kerng.constrain_positive()\n",
    "    m.kernf.f_white.fix()\n",
    "    m.kerng.g_white.fix()\n",
    "    \n",
    "    if hasattr(m, 'constmap'):\n",
    "        m.constmap.unfix()\n",
    "\n",
    "    # Continue with optimization with everything released\n",
    "    m.optimize('scg', max_iters=1*preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "    m.optimize('bfgs', max_iters=5*preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "\n",
    "    return m\n",
    "\n",
    "m2 = pretrain_multi(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i     f              |g|        \n",
      "    03s24  011  -2.088977e+02   4.417058e+02 \n",
      "    11s08  045  -2.107318e+02   8.718107e+01 \n",
      "    23s68  102  -2.115608e+02   2.330801e+02 \n",
      "Runtime:     23s68\n",
      "Optimization status: Maximum number of f evaluations reached\n",
      "\n",
      "\n",
      "Name : multi_gauss\n",
      "Objective : -211.56077992172027\n",
      "Number of Parameters : 61228\n",
      "Number of Optimization Parameters : 61226\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mmulti_gauss.               \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |           (240, 12)  |               |        \n",
      "  \u001b[1mq_u_means                  \u001b[0;0m  |            (240, 2)  |               |        \n",
      "  \u001b[1mqf_u_chols                 \u001b[0;0m  |          (28920, 2)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |  0.6969623585716113  |      +ve      |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |               (12,)  |      +ve      |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |               0.001  |   +ve fixed   |        \n",
      "  \u001b[1mkerng.kerng_rbf.variance   \u001b[0;0m  |   6.776512811293102  |      +ve      |        \n",
      "  \u001b[1mkerng.kerng_rbf.lengthscale\u001b[0;0m  |               (12,)  |      +ve      |        \n",
      "  \u001b[1mkerng.g_white.variance     \u001b[0;0m  |               0.001  |   +ve fixed   |        \n",
      "[[0.30679667]\n",
      " [0.18356971]\n",
      " [0.1873331 ]\n",
      " [0.29307823]\n",
      " [0.13901015]\n",
      " [0.33286999]\n",
      " [0.25610281]\n",
      " [0.18338848]\n",
      " [0.47872753]\n",
      " [0.0727013 ]\n",
      " [0.30312284]\n",
      " [0.30976332]\n",
      " [0.40062319]\n",
      " [0.16666934]\n",
      " [0.38170816]\n",
      " [0.15587548]\n",
      " [0.31383167]\n",
      " [0.25454022]\n",
      " [0.13549307]\n",
      " [0.35852242]\n",
      " [0.12041282]\n",
      " [0.29113891]\n",
      " [0.10643227]\n",
      " [0.42918869]\n",
      " [0.51982853]\n",
      " [0.43200816]\n",
      " [0.20498151]\n",
      " [0.16166742]\n",
      " [0.18966337]\n",
      " [0.07552543]\n",
      " [0.19872899]\n",
      " [0.29218184]\n",
      " [0.28655063]\n",
      " [0.15483209]\n",
      " [0.20029038]\n",
      " [0.07028998]\n",
      " [0.03017555]\n",
      " [0.2965756 ]\n",
      " [0.54467775]\n",
      " [0.5660777 ]\n",
      " [0.31991699]\n",
      " [0.35048074]\n",
      " [0.31560798]\n",
      " [0.10175101]\n",
      " [0.06775854]\n",
      " [0.5249013 ]\n",
      " [0.20825985]\n",
      " [0.25658219]\n",
      " [0.18719354]\n",
      " [0.12204644]\n",
      " [0.43550265]\n",
      " [0.11397534]\n",
      " [0.10392424]\n",
      " [0.19510234]\n",
      " [0.26494797]\n",
      " [0.19932206]\n",
      " [0.14040674]\n",
      " [0.23714875]\n",
      " [0.16765762]\n",
      " [0.21583009]]\n",
      "train: {'Mean Squared Error (MSE)': 0.013349627, 'Mean Absolute Error (MAE)': 0.07920434, 'R-squared (R2)': 0.6529741}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m2.Z.unfix()\n",
    "m2.optimize('bfgs', max_iters=100, messages=1)\n",
    "print(m2)\n",
    "mu_multi_gauss, _ = m2._raw_predict(Xtest, 0)\n",
    "var_multi_gauss, _ = m2._raw_predict(Xtest, 1)\n",
    "print(mu_multi_gauss)\n",
    "metrics = regression_metrics(y_true=Ytest, y_pred=mu_multi_gauss)\n",
    "print(f'train: {metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mindex\u001b[0;0m  |  multi_gauss.kernf.kernf_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                               1.46490385  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                              10.07374433  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                              21.11842779  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                              20.21164497  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                               0.95236993  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                              22.39178498  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                              19.69921597  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                               1.65109865  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                              20.81272575  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                              21.63001540  |      +ve      |        \n",
      "  \u001b[1m[10] \u001b[0;0m  |                               1.56246943  |      +ve      |        \n",
      "  \u001b[1m[11] \u001b[0;0m  |                               0.84200775  |      +ve      |        \n",
      "  \u001b[1mindex\u001b[0;0m  |  multi_gauss.kerng.kerng_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                               1.06779084  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                              10.66499561  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                              11.18894331  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                              10.90982109  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                              11.07959698  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                              11.06980872  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                              10.77761610  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                              12.74499500  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                              11.80262474  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                              11.57589546  |      +ve      |        \n",
      "  \u001b[1m[10] \u001b[0;0m  |                              10.32110240  |      +ve      |        \n",
      "  \u001b[1m[11] \u001b[0;0m  |                               9.84055135  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "print(m2.kernf.kernf_rbf.lengthscale)\n",
    "print(m2.kerng.kerng_rbf.lengthscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.813688182440948"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.log_predictive_density(Xtest, Ytest).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histograms(vector1, vector2, bins=100, alpha=0.65, label1='abs-error', label2='std'):\n",
    "    # Plot histograms for the two vectors\n",
    "    plt.hist(vector1, bins=bins, alpha=alpha, label=label1)\n",
    "    plt.hist(vector2, bins=bins, alpha=alpha, label=label2)\n",
    "    \n",
    "    # Adding legend to differentiate the two vectors\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    # Labels and title for clarity\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram')\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m2.log_predictive_density(Xtest, Ytest).mean()\n",
    "abs_error = np.abs(mu_multi_gauss - Ytest)\n",
    "std = np.sqrt(np.exp(var_multi_gauss))\n",
    "plot_histograms(abs_error, std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
