{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motorcycle dataset analysis, found at http://vincentarelbundock.github.io/Rdatasets/datasets.html under 'mcycle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import GPy\n",
    "import numpy as np\n",
    "from hetgp import HetGP\n",
    "from svgp_multi import SVGPMulti\n",
    "from sklearn.metrics import (r2_score, mean_squared_error, mean_absolute_error)\n",
    "data_dir = './modx_data/'\n",
    "\n",
    "def regression_metrics(y_true: np.array, y_pred: np.array):\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        'Mean Squared Error (MSE)': np.float32(mse),\n",
    "        'Mean Absolute Error (MAE)': np.float32(mae),\n",
    "        'R-squared (R2)': np.float32(r2),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restarts = 10\n",
    "n_folds = 5\n",
    "Ms = ['all'] #, 100]\n",
    "#These are just starting values, lengthscales will also be randomized\n",
    "f_rbf_len = 1 # 0.3\n",
    "f_rbf_var = 0.5 # 0.5\n",
    "g_rbf_len = 1 # 0.5\n",
    "g_rbf_var = 0.5 # 0.5\n",
    "\n",
    "# This is the log of mean of the posterior of the scale parameter, so we set it\n",
    "# to be the log of roughly what we expect the scale parameter to be if it were\n",
    "# constant\n",
    "\n",
    "gauss_noise = 0.1\n",
    "g_mean_val = None  # np.log(gauss_noise)\n",
    "g_bias_var = None\n",
    "f_bias_var = None # ['mean']\n",
    "fixZ = True\n",
    "preopt_scg_iters = 100\n",
    "preopt_restarts = 3\n",
    "scg_iters = 50\n",
    "max_iters = 250\n",
    "num_samples = 100000\n",
    "gtol = 1e-5\n",
    "ftol = 0\n",
    "xtol = 0\n",
    "starting_df = 4.0\n",
    "optimize_df = True\n",
    "\n",
    "fold = 0\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "name = 'sim1.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_tsv(path: str, name: str):\n",
    "    return pd.read_csv(os.path.join(path, name), sep='\\t')\n",
    "\n",
    "def std_matrices(*mts):\n",
    "    std_mts = []\n",
    "    for mats in mts:\n",
    "        if isinstance(mats, np.ndarray):  # Single matrix case\n",
    "            mats = [mats]\n",
    "        for mat in mats:\n",
    "            min_vals = np.min(mat, axis=0)\n",
    "            max_vals = np.max(mat, axis=0)\n",
    "            std_mat = (mat - min_vals) / (max_vals - min_vals)\n",
    "            std_mts.append(std_mat)\n",
    "    return tuple(std_mts)\n",
    "\n",
    "def holdout_split(\n",
    "        df,\n",
    "        test_size: float = 0.2,\n",
    "        random_state: int = None,\n",
    "    ):\n",
    "    y = df.Y.values\n",
    "    x = df.values[:, :-1]\n",
    "    return train_test_split(\n",
    "            x, y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape:  (160, 10)\n",
      "test shape:  (40, 10)\n",
      "All:  (200, 10)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, Xtrain, Ytrain, Xtest, Ytest):\n",
    "        self.Xtrain, self.Ytrain, self.Xtest, self.Ytest = Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "def load_modx(seed):\n",
    "\n",
    "    df = read_tsv(path=data_dir, name=name)    \n",
    "    Y = df.Y.values\n",
    "    X = df.values[:, :-1]\n",
    "    Xtrain, Xtest, Ytrain, Ytest = std_matrices(\n",
    "        holdout_split(\n",
    "            df=read_tsv(path=data_dir, name=name),\n",
    "            random_state=seed\n",
    "            )\n",
    "        )\n",
    "    Ytrain = Ytrain[:, None]\n",
    "    Ytest = Ytest[:, None]\n",
    "    print(\"training shape: \", Xtrain.shape)\n",
    "    print(\"test shape: \", Xtest.shape)\n",
    "    print(\"All: \", X.shape)\n",
    "    print(Xtrain.shape[0] + Xtest.shape[0] - X.shape[0])\n",
    "    return Dataset(Xtrain=Xtrain, Ytrain=Ytrain, Xtest=Xtest, Ytest=Ytest), X, Y\n",
    "\n",
    "dataset, X, Y = load_modx(seed)\n",
    "\n",
    "Xtrain = dataset.Xtrain\n",
    "Ytrain = dataset.Ytrain\n",
    "Xtest = dataset.Xtest\n",
    "Ytest = dataset.Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters gauss_single.kernf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreOptimizing gauss  \n",
      "Name : gauss_single\n",
      "Objective : 42.542836085432675\n",
      "Number of Parameters : 1613\n",
      "Number of Optimization Parameters : 1612\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mgauss_single.              \u001b[0;0m  |      value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |  (160, 10)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |        0.5  |      +ve      |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |      (10,)  |      +ve      |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |      0.001  |   +ve fixed   |        \n",
      "  \u001b[1mGaussian_noise.variance    \u001b[0;0m  |        0.1  |      +ve      |        \n",
      "  \u001b[1mindex\u001b[0;0m  |  gauss_single.kernf.kernf_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                                1.00000000  |      +ve      |        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters gauss_single.Gaussian_noise.variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i     f              |g|        \n",
      "WARNING: l-bfgs-b doesn't have an xtol arg, so I'm going to ignore it\n",
      "WARNING: l-bfgs-b doesn't have an ftol arg, so I'm going to ignore it\n",
      "    01s18  009  -1.861510e+02   3.843677e+03 \n",
      "    06s56  050  -5.556037e+02   3.450496e+03 \n",
      "    13s32  102  -5.999273e+02   8.835032e+02 \n",
      "Runtime:     13s32\n",
      "Optimization status: Maximum number of f evaluations reached\n",
      "\n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i     f              |g|        \n",
      "WARNING: l-bfgs-b doesn't have an xtol arg, so I'm going to ignore it\n",
      "WARNING: l-bfgs-b doesn't have an ftol arg, so I'm going to ignore it\n",
      "    00s00  000  -5.999273e+02   8.835032e+02 \n",
      "    00s18  002  -6.001171e+02   1.724813e+06 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/rbarbano/projects/dev/ChainedGP/myenv/lib/python3.6/site-packages/paramz/transformations.py:111: RuntimeWarning:overflow encountered in expm1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    02s37  018  -5.999273e+02   4.861158e+06 \n",
      "    07s77  059  -5.999273e+02   4.861158e+06 \n",
      "Runtime:     07s77\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "Found best gauss model\n",
      "\n",
      "Name : gauss_single\n",
      "Objective : -599.9273185920902\n",
      "Number of Parameters : 1613\n",
      "Number of Optimization Parameters : 1613\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mgauss_single.              \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |               (160, 10)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |       68.25683120607069  |      +ve      |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |                   (10,)  |      +ve      |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |  5.562684646268137e-309  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance    \u001b[0;0m  |   5.576744601325087e-06  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s00  0000  -5.999273e+02           nan \n",
      "    02s08  0015  -5.999273e+02   7.297360e+06 \n",
      "    02s98  0022  -5.999272e+02   4.861158e+06 \n",
      "Runtime:     02s98\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "\n",
      "Name : gauss_single\n",
      "Objective : -599.9273185920902\n",
      "Number of Parameters : 1613\n",
      "Number of Optimization Parameters : 1612\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mgauss_single.              \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |               (160, 10)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |       68.25683120607069  |      +ve      |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |                   (10,)  |      +ve      |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |  5.562684646268137e-309  |   +ve fixed   |        \n",
      "  \u001b[1mGaussian_noise.variance    \u001b[0;0m  |   5.576744601325087e-06  |      +ve      |        \n",
      "  \u001b[1mindex\u001b[0;0m  |  gauss_single.kernf.kernf_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                              756.97959394  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                              764.63225161  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                              812.04551821  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                                0.35191865  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                               15.59571792  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                              737.84537055  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                              679.53887890  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                              869.67485842  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                              809.48105866  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                              694.90897553  |      +ve      |        \n",
      "[[0.01118643]\n",
      " [0.01757665]\n",
      " [0.01728926]\n",
      " [0.1141869 ]\n",
      " [0.00815327]\n",
      " [0.68086755]\n",
      " [0.00571133]\n",
      " [0.00842327]\n",
      " [0.00709841]\n",
      " [0.59414236]\n",
      " [0.00685416]\n",
      " [0.01015729]\n",
      " [0.00907495]\n",
      " [0.01276496]\n",
      " [0.00902712]\n",
      " [0.5527783 ]\n",
      " [0.00507159]\n",
      " [0.00773375]\n",
      " [0.01427751]\n",
      " [0.11048546]\n",
      " [0.02592945]\n",
      " [0.15781127]\n",
      " [0.16137197]\n",
      " [0.00442679]\n",
      " [0.29668001]\n",
      " [0.00567959]\n",
      " [0.92206099]\n",
      " [0.00340344]\n",
      " [0.251835  ]\n",
      " [0.1070149 ]\n",
      " [0.0151236 ]\n",
      " [0.00429974]\n",
      " [0.63550273]\n",
      " [0.01107151]\n",
      " [0.01489042]\n",
      " [0.88298423]\n",
      " [0.00786222]\n",
      " [0.84138887]\n",
      " [0.01180742]\n",
      " [0.96937498]]\n",
      "train: {'Mean Squared Error (MSE)': 0.0048731505, 'Mean Absolute Error (MAE)': 0.03534365, 'R-squared (R2)': 0.92518115}\n"
     ]
    }
   ],
   "source": [
    "def build_kernf(D, dataset, bias, f_rbf_len, f_rbf_var, seed, fold):\n",
    "    kernf = GPy.kern.RBF(D, variance=f_rbf_var,\n",
    "                         lengthscale=np.ones(D)*f_rbf_len, ARD=True,\n",
    "                         name='kernf_rbf')\n",
    "    kernf += GPy.kern.White(1, variance=0.001, name='f_white')\n",
    "    if bias is not None:\n",
    "        if bias == 'mean':\n",
    "            f_bias_var = dataset.Ytrain.mean()\n",
    "        else:\n",
    "            f_bias_var = bias\n",
    "            kernf += GPy.kern.Bias(1, variance=f_bias_var, name='f_bias')\n",
    "    kernf.f_white.fix()\n",
    "    kernf.name = 'kernf'\n",
    "    return kernf\n",
    "\n",
    "def build_kerng(D, g_bias, g_rbf_len, seed, fold):\n",
    "    # Needs white or variance doesn't checkgrad!\n",
    "    kerng = GPy.kern.RBF(D, variance=g_rbf_var,\n",
    "                         lengthscale=np.ones(D)*g_rbf_len, ARD=True,\n",
    "                         name='kerng_rbf')\n",
    "    kerng += GPy.kern.White(1, variance=0.001, name='g_white')\n",
    "    if g_bias is not None:\n",
    "        kerng += GPy.kern.Bias(1, variance=g_bias, name='g_bias')\n",
    "    kerng.g_white.fix()\n",
    "    kerng.name = 'kerng'\n",
    "    return kerng\n",
    "\n",
    "from scipy.cluster.vq import kmeans as scipy_kmeans\n",
    "\n",
    "def kmeans(dataset, k, seed):\n",
    "    Z, _ = scipy_kmeans(dataset.Xtrain, k)\n",
    "    return Z\n",
    "\n",
    "def build_gauss_model(dataset, Z, fixZ, bias, f_rbf_len, f_rbf_var, seed, fold):\n",
    "    D = dataset.Xtrain.shape[1]\n",
    "    kernf = build_kernf(D, dataset, bias, f_rbf_len, f_rbf_var, seed, fold)\n",
    "    m_gauss = GPy.models.SparseGPRegression(dataset.Xtrain.copy(), dataset.Ytrain.copy(), Z=Z.copy(), kernel=kernf)\n",
    "    m_gauss.name='gauss_single'\n",
    "    m_gauss.likelihood.variance[:] = gauss_noise\n",
    "    return m_gauss\n",
    "\n",
    "def preopt_gauss_scheme(m):\n",
    "    m.kernf.constrain_positive()\n",
    "    m.likelihood.variance.constrain_positive()\n",
    "    if hasattr(m, 'Z'):\n",
    "        m.Z.fix()\n",
    "    m.optimize('bfgs', max_iters=preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "    if hasattr(m, 'Z'):\n",
    "        m.Z.unfix()\n",
    "    m.optimize('bfgs', max_iters=5*preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "    return m\n",
    "\n",
    "def preopt_gauss(dataset, Z, fixZ, bias, f_rbf_len, f_rbf_var, seed, fold):\n",
    "    m = build_gauss_model(dataset, Z, fixZ, bias, f_rbf_len, f_rbf_var, seed, fold)\n",
    "    print(\"PreOptimizing gauss \", m)\n",
    "    print(m.kernf.kernf_rbf.lengthscale)\n",
    "    best_m = preopt_gauss_scheme(m)\n",
    "    print(\"Found best gauss model\")\n",
    "    print(best_m)\n",
    "    return best_m[:]\n",
    "\n",
    "m1_opt = preopt_gauss(dataset, Xtrain.copy(), fixZ, f_bias_var, f_rbf_len, f_rbf_var, seed, fold)\n",
    "m1 = build_gauss_model(dataset, Xtrain.copy(), fixZ, f_bias_var, f_rbf_len, f_rbf_var, seed, fold)\n",
    "m1[:] = m1_opt\n",
    "\n",
    "m1.Z.unfix()\n",
    "m1.optimize('bfgs', max_iters=3000, messages=1)\n",
    "print(m1)\n",
    "print(m1.kernf.kernf_rbf.lengthscale)\n",
    "mu_gauss, var_gauss = m1.predict(Xtest)\n",
    "\n",
    "print(mu_gauss)\n",
    "metrics = regression_metrics(y_true=Ytest, y_pred=mu_gauss)\n",
    "print(f'train: {metrics}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-175.6409466694917"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.log_predictive_density(Xtest, Ytest).mean()\n",
    "# print(m1.kernf.kernf_rbf.lengthscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error = np.abs(mu_gauss - Ytest)\n",
    "std = np.sqrt(var_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histograms(vector1, vector2, bins=100, alpha=0.65, label1='abs-error', label2='std'):\n",
    "    # Plot histograms for the two vectors\n",
    "    plt.hist(vector1, bins=bins, alpha=alpha, label=label1)\n",
    "    plt.hist(vector2, bins=bins, alpha=alpha, label=label2)\n",
    "    \n",
    "    # Adding legend to differentiate the two vectors\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    # Labels and title for clarity\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.title('Histogram')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_histograms(abs_error, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_multi_lengthscales(X_):\n",
    "    normed_X = (X_.max(0) - X_.min(0))/X_.std(0)\n",
    "    # print(normed_X)\n",
    "    f_lengthscales = np.random.uniform(size=X_.shape[1])*(0.4/normed_X) + 0.001\n",
    "    g_lengthscales = np.random.uniform(size=X_.shape[1])*(0.4/normed_X) + 0.001\n",
    "    # print(f_lengthscales)\n",
    "    return f_lengthscales, g_lengthscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name : multi_gauss\n",
      "Objective : 8277.50960865245\n",
      "Number of Parameters : 27704\n",
      "Number of Optimization Parameters : 26080\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mmulti_gauss.               \u001b[0;0m  |       value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |   (160, 10)  |     fixed     |        \n",
      "  \u001b[1mq_u_means                  \u001b[0;0m  |    (160, 2)  |               |        \n",
      "  \u001b[1mqf_u_chols                 \u001b[0;0m  |  (12880, 2)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |         0.5  |   +ve fixed   |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |       (10,)  |   +ve fixed   |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |       0.001  |   +ve fixed   |        \n",
      "  \u001b[1mkerng.kerng_rbf.variance   \u001b[0;0m  |         0.5  |   +ve fixed   |        \n",
      "  \u001b[1mkerng.kerng_rbf.lengthscale\u001b[0;0m  |       (10,)  |   +ve fixed   |        \n",
      "  \u001b[1mkerng.g_white.variance     \u001b[0;0m  |       0.001  |   +ve fixed   |        \n",
      "Running Scaled Conjugate Gradients Code:\n",
      "  runtime   i     f              |g|        \n",
      "    00s14  004   2.293016e+03   1.772885e+06 \n",
      "    00s18  005   2.293016e+03   6.479805e+05 \n",
      "    01s19  032   2.895868e+02   1.350463e+04 \n",
      "    03s21  101   1.271240e+02   7.454264e+02 \n",
      "    05s26  171   5.500357e+01   2.094241e+02 \n",
      "    09s09  302   4.155173e+01   1.602319e+01 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters multi_gauss.kernf\n",
      "reconstraining parameters multi_gauss.kerng\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runtime:     09s09\n",
      "Optimization status: maxiter exceeded\n",
      "\n",
      "Running Scaled Conjugate Gradients Code:\n",
      "  runtime   i     f              |g|        \n",
      "    00s14  002   4.155173e+01   1.385252e+03 \n",
      "    03s22  048  -3.946974e+01   2.681232e+03 \n",
      "    11s56  172  -1.311013e+02   1.003780e+03 \n",
      "    20s44  302  -1.841570e+02   9.628686e+02 \n",
      "Runtime:     20s44\n",
      "Optimization status: maxiter exceeded\n",
      "\n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i     f              |g|        \n",
      "WARNING: l-bfgs-b doesn't have an xtol arg, so I'm going to ignore it\n",
      "WARNING: l-bfgs-b doesn't have an ftol arg, so I'm going to ignore it\n",
      "    01s14  015  -1.886282e+02   4.306771e+02 \n",
      "    05s29  074  -2.096128e+02   2.436646e+02 \n",
      "    17s87  242  -2.418667e+02   6.451987e+01 \n",
      "    26s14  354  -2.511921e+02   1.830094e+01 \n",
      "    37s10  502  -2.525876e+02   5.520614e+00 \n",
      "Runtime:     37s10\n",
      "Optimization status: Maximum number of f evaluations reached\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make the kernels : \n",
    "D = dataset.Xtrain.shape[1]\n",
    "kernf = build_kernf(D, dataset, f_bias_var, f_rbf_len, f_rbf_var, seed, fold)\n",
    "kerng = build_kerng(D, g_bias_var, g_rbf_len, seed, fold)\n",
    "kern = [kernf, kerng]\n",
    "mean_functions = [None, None]\n",
    "likelihood = HetGP()\n",
    "\n",
    "Z = dataset.Xtrain.copy()\n",
    "\n",
    "# Make the model : \n",
    "m2 = SVGPMulti(dataset.Xtrain.copy(), dataset.Ytrain.copy(), Z.copy(), kern_list=kern,\n",
    "                    likelihood=likelihood, mean_functions=mean_functions, name='multi_gauss')\n",
    "\n",
    "\n",
    "def pretrain_multi(m, randomize=False):\n",
    "    if randomize:\n",
    "        f_lens, g_lens = random_multi_lengthscales(m.X.values)\n",
    "        m.kernf.kernf_rbf.lengthscale[:] = f_lens\n",
    "        m.kernf.kernf_rbf.variance[:] = f_rbf_var\n",
    "        m.kerng.kerng_rbf.lengthscale[:] = g_lens\n",
    "        m.kerng.kerng_rbf.variance[:] = g_rbf_var\n",
    "    m.kernf.fix()\n",
    "    m.kerng.fix()\n",
    "    if hasattr(m, 'Z'):\n",
    "        m.Z.fix()\n",
    "    if hasattr(m, 'constmap'):\n",
    "        m.constmap.fix()\n",
    "    print(m)\n",
    "\n",
    "    # Optimize model with fixed parameters to get latent functions in place\n",
    "    m.optimize('scg', max_iters=1*preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "    \n",
    "    # Constrain all kernel parameters positive and reoptimize\n",
    "    m.kernf.constrain_positive()\n",
    "    m.kerng.constrain_positive()\n",
    "    m.kernf.f_white.fix()\n",
    "    m.kerng.g_white.fix()\n",
    "    \n",
    "    if hasattr(m, 'constmap'):\n",
    "        m.constmap.unfix()\n",
    "\n",
    "    # Continue with optimization with everything released\n",
    "    m.optimize('scg', max_iters=1*preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "    m.optimize('bfgs', max_iters=5*preopt_scg_iters, gtol=gtol, messages=1, xtol=xtol, ftol=ftol)\n",
    "\n",
    "    return m\n",
    "\n",
    "m2 = pretrain_multi(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i     f              |g|        \n",
      "    01s18  006  -2.525956e+02   3.332353e+01 \n",
      "    05s57  030  -2.529816e+02   5.053768e+02 \n",
      "    18s59  098  -2.534571e+02   1.021087e+02 \n",
      "    19s32  102  -2.534632e+02   6.344012e+01 \n",
      "Runtime:     19s32\n",
      "Optimization status: Maximum number of f evaluations reached\n",
      "\n",
      "\n",
      "Name : multi_gauss\n",
      "Objective : -253.46319018990044\n",
      "Number of Parameters : 27704\n",
      "Number of Optimization Parameters : 27702\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mmulti_gauss.               \u001b[0;0m  |                value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs            \u001b[0;0m  |            (160, 10)  |               |        \n",
      "  \u001b[1mq_u_means                  \u001b[0;0m  |             (160, 2)  |               |        \n",
      "  \u001b[1mqf_u_chols                 \u001b[0;0m  |           (12880, 2)  |               |        \n",
      "  \u001b[1mkernf.kernf_rbf.variance   \u001b[0;0m  |  0.32683178813423186  |      +ve      |        \n",
      "  \u001b[1mkernf.kernf_rbf.lengthscale\u001b[0;0m  |                (10,)  |      +ve      |        \n",
      "  \u001b[1mkernf.f_white.variance     \u001b[0;0m  |                0.001  |   +ve fixed   |        \n",
      "  \u001b[1mkerng.kerng_rbf.variance   \u001b[0;0m  |   13.741981169843712  |      +ve      |        \n",
      "  \u001b[1mkerng.kerng_rbf.lengthscale\u001b[0;0m  |                (10,)  |      +ve      |        \n",
      "  \u001b[1mkerng.g_white.variance     \u001b[0;0m  |                0.001  |   +ve fixed   |        \n",
      "[[0.01010152]\n",
      " [0.02386507]\n",
      " [0.01272003]\n",
      " [0.11552505]\n",
      " [0.00686497]\n",
      " [0.69823142]\n",
      " [0.00564761]\n",
      " [0.00773796]\n",
      " [0.01276432]\n",
      " [0.61366357]\n",
      " [0.00794933]\n",
      " [0.00760954]\n",
      " [0.00710645]\n",
      " [0.00755034]\n",
      " [0.00968468]\n",
      " [0.56916249]\n",
      " [0.00930635]\n",
      " [0.00819142]\n",
      " [0.00729908]\n",
      " [0.10897602]\n",
      " [0.02943295]\n",
      " [0.13860344]\n",
      " [0.15930525]\n",
      " [0.00768838]\n",
      " [0.28367125]\n",
      " [0.00669972]\n",
      " [0.89867849]\n",
      " [0.00806703]\n",
      " [0.23233945]\n",
      " [0.09820842]\n",
      " [0.00582084]\n",
      " [0.00748855]\n",
      " [0.63137176]\n",
      " [0.01183713]\n",
      " [0.02041408]\n",
      " [0.8684037 ]\n",
      " [0.00967623]\n",
      " [0.81820196]\n",
      " [0.00553192]\n",
      " [0.94921016]]\n",
      "train: {'Mean Squared Error (MSE)': 0.004695227, 'Mean Absolute Error (MAE)': 0.036978137, 'R-squared (R2)': 0.92791283}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m2.Z.unfix()\n",
    "m2.optimize('bfgs', max_iters=100, messages=1)\n",
    "print(m2)\n",
    "mu_multi_gauss, _ = m2._raw_predict(Xtest, 0)\n",
    "var_multi_gauss, _ = m2._raw_predict(Xtest, 1)\n",
    "print(mu_multi_gauss)\n",
    "metrics = regression_metrics(y_true=Ytest, y_pred=mu_multi_gauss)\n",
    "print(f'train: {metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mindex\u001b[0;0m  |  multi_gauss.kernf.kernf_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                              44.69883084  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                              44.57385836  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                              45.73080756  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                               0.14600240  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                              40.93417553  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                              45.51459736  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                              45.67452599  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                              46.45460336  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                              45.23181218  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                              46.03118069  |      +ve      |        \n",
      "  \u001b[1mindex\u001b[0;0m  |  multi_gauss.kerng.kerng_rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                              23.09001544  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                              23.95066025  |      +ve      |        \n",
      "  \u001b[1m[2]  \u001b[0;0m  |                              24.06616693  |      +ve      |        \n",
      "  \u001b[1m[3]  \u001b[0;0m  |                              12.65660720  |      +ve      |        \n",
      "  \u001b[1m[4]  \u001b[0;0m  |                              16.53915891  |      +ve      |        \n",
      "  \u001b[1m[5]  \u001b[0;0m  |                              23.46972480  |      +ve      |        \n",
      "  \u001b[1m[6]  \u001b[0;0m  |                              21.61916059  |      +ve      |        \n",
      "  \u001b[1m[7]  \u001b[0;0m  |                              23.79216876  |      +ve      |        \n",
      "  \u001b[1m[8]  \u001b[0;0m  |                              23.31155545  |      +ve      |        \n",
      "  \u001b[1m[9]  \u001b[0;0m  |                              23.34203205  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "print(m2.kernf.kernf_rbf.lengthscale)\n",
    "print(m2.kerng.kerng_rbf.lengthscale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
